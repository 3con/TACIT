<html>
	<head>
		<link rel="stylesheet" type="text/css" href="sample.css">
	</head>
	<body>
		<center><h3>TACIT User Guide</h3></center>
		<hr>
		<table style = "border:0px; width:100%" class = "help-contents">
			<tr>
				<td class = "header">TACIT Twitter Crawler</td>
			</tr>
			<tr>
				<table class = "contents">
					<tr>
						<td class = "head">Overview</td>
					</tr>
					<tr>
						<td>The Twitter Crawler tool collects text from <a href = "http://www.twitter.com/" target="_blank">the Twitter website</a> and writes that data into text files that are readable by automated text analysis programs. <br><br> 
						<br><br> 	
						</td>
					</tr>
				</table>
			</tr>
			<tr>
				<table class = "contents">
					<tr>
						<td class = "head">Basic Tutorial: Collecting data using Twitter Crawler</td>
					</tr>
					<tr>
						<td class = "subtitle">Selecting Parameters</td>
					</tr>
					<tr>
						<td>Description
						</td>
					</tr>
					<tr>
						<td class = "subtitle">Specifying Output Folder</td>
					</tr>
					<tr>
						<td>To specify an output folder where crawled files will be saved, click on the <b>Browse</b> button to the right of the Output Location bar and select a folder. After specifying all parameters, click the <b>green and white play button</b> located in the top right corner of the window to run the program. Output information will display in the console panel at the bottom of the tool. 
						<b> Note: </b> The program will create a new folder for each author requested and it will save all files by that author within that folder. Sub-folders will also be generated for document files from collected works.
 							<br><br>	
						</td>
					</tr>
					<tr>
						<td class = "subtitle">Understanding Twitter Crawler Output</td>
					</tr>
					<tr>
						<td> Describe data output files.
						</td>
					</tr>					
				</table>
			</tr>	
		</table>
	</body>
</html>
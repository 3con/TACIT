<html>
	<head>
		<link rel="stylesheet" type="text/css" href="sample.css">
	</head>
	<body>
		<center><h3>TACIT User Guide</h3></center>
		<hr>
		<table style = "border:0px; width:100%" class = "help-contents">
			<tr>
				<td class = "header">TACIT Twitter Crawler</td>
			</tr>
			<tr>
				<table class = "contents">
					<tr>
						<td class = "head">Overview</td>
					</tr>
					<tr>
						<td>The Twitter Crawler tool collects text from <a href = "http://www.twitter.com/" target="_blank">the Twitter website</a> and writes that data into text files that are readable by automated text analysis programs. <br><br> 
						<br><br> 	
						</td>
					</tr>
				</table>
			</tr>
			<tr>
				<table class = "contents">
					<tr>
						<td class = "head">Basic Tutorial: Collecting data using Twitter Crawler</td>
					</tr>
					<tr>
						<td class = "subtitle">Setting Up Account Authorization</td>
					</tr>
					<tr>
						<td>Before you can crawl data, Twitter requires specific account-tied authorization information to crawl their website. To acquire this authentication information from Twitter:	
						<br>1. Go to  http://twitter.com/apps and log into your twitter account (or create an account if you don't already have one).
						<br>2. The creation Application page will open. Click on Create Application.
						<br>3. Fill in the TACIT crawler specifications 
								<br>	application name: [name that will help you keep track of your data]
								<br>	app description: [description that will help you keep track of your data]
								<br>	website: http://cssl.usc.edu
								<br>	callback url: [leave blank]
						<br>4. You will then be provided an overview page with details about the application you just set up for crawling. Click on the  Keys and Access Tokens Tab. Here, you  will find the information needed for the TACIT Twitter User Configuration form. Copy the Consumer key and Consumer secret into the TACIT preferences page.
						<br>5. At the bottom of the page under Token Actions, click Generate My Access Token. Copy the Access Token and Access Token Secret into the TACIT preferences page and click apply. Your name should appear in the grey User Name box if the information was entered successfully. Click OK to close the preferences page.
						<br> Step-by-step instructions with pictures can be found <a href = "https://code.google.com/p/socialauth-android/wiki/Twitter" target="_blank">here</a>.
						</td>
					</tr>
					<tr>
						<td class = "subtitle">Crawler Filters</td>
					</tr>
					<tr>
						<td>Twitter data can be crawled based on keywords (Word Filter) or locations (Geo Filter) of interest.
						</td>
					</tr>
					<tr>
						<td class = "section">Word Filter</td>
					</tr>
					<tr>
						<td class = "section">Geo Filter</td>
					</tr>
					<tr>
						<td>To determine the bounding box needed for your area of interest, you can use the tool available at http://boundingbox.klokantech.com/. Change the <b>Copy & Paste</b> option in the bottom panel drop down menu to CSV. You can then enter in the name of the city, state, or country you want to crawl or click and drag the selection box on the map to the desired location. The geo-coordiate box for that area will appear at the bottom of the page. Copy paste these numbers into the Geo Filter box in the TACIT tool. If you would like to crawl from multiple distinct locations, simply add the geo-coordiate box for each location into the tool separated by semi-colons.
						</td>
					</tr>
					<tr>
						<td class = "subtitle">Tweet Limits</td>
					</tr>
					<tr>
						<td class = "section">Time Limit</td>
					</tr>
					<tr>
						<td>For events that are infrequent or that you expect to unfold over a certain time frame, you can specify a length of time that the tool should continue to run and crawl data. TACIT will  collect tweets as long as the program remains running on your computer and you continue to be connected to the Internet.	
						</td>
					</tr>
					<tr>
						<td class = "section">Maximum Limit</td>
					</tr>
					<tr>
						<td>The Twitter crawler is automatically set to download 10 total tweets per request. This option can be changed to any number of tweets you are interested in collecting. The tool will continue to run until the number is reached.	
						</td>
					</tr>
					<tr>
						<td>	
						</td>
					<tr>
						<td class = "subtitle">Specifying Output Folder</td>
					</tr>
					<tr>
						<td>To specify an output folder where crawled files will be saved, click on the <b>Browse</b> button to the right of the Output Location bar and select a folder. After specifying all parameters, click the <b>green and white play button</b> located in the top right corner of the window to run the program. Output information will display in the console panel at the bottom of the tool. 
						<b> Note: </b> The program will create a new folder for each author requested and it will save all files by that author within that folder. Sub-folders will also be generated for document files from collected works.
 							<br><br>	
						</td>
					</tr>
					<tr>
						<td class = "subtitle">Understanding Twitter Crawler Output</td>
					</tr>
					<tr>
						<td> Describe data output files.
						</td>
					</tr>					
				</table>
			</tr>	
		</table>
	</body>
</html>